{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9f045b",
   "metadata": {},
   "source": [
    "### 自定义块\n",
    "- 实现一个简单的MLP类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c3eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 隐藏层\n",
    "        self.out = nn.Linear(256, 10) # 输出层\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18332fe",
   "metadata": {},
   "source": [
    "- 实现一个MySequential类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949874f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。_modules的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a052331",
   "metadata": {},
   "source": [
    "- 实现一个带参数的MyLinear层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea047ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30c2cc",
   "metadata": {},
   "source": [
    "### 1 框架示例\n",
    "使用PyTorch构建模型时，通常涉及到自定义块这个概念。自定义块就是模型中的一层或者一块，是用于创建网络实体的类。\n",
    "\n",
    "这里给出一个基本代码框架，然后进行解释："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81afe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModule(nn.Module):\n",
    "    # 初始化模块的参数或子模块\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomModule, self).__init__()\n",
    "\n",
    "        # 示例：定义一个线性层\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "        # 示例：定义一个可重用的ReLU激活层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    # 定义前向传播的计算\n",
    "    def forward(self, x):\n",
    "        # 示例：通过定义的层传递输入\n",
    "        x = self.linear(x)  # 输入通过线性层\n",
    "        x = self.relu(x)    # 通过ReLU激活层\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240fb4a8",
   "metadata": {},
   "source": [
    "**类定义**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f09476",
   "metadata": {},
   "source": [
    "class CustomModule(nn.Module):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3abf8c",
   "metadata": {},
   "source": [
    "CustomModule 类继承自 nn.Module，即 PyTorch 中所有神经网络模块的基类。继承 nn.Module 允许 CustomModule 使用 PyTorch 的自动梯度计算、参数管理、模型保存/加载等功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b80357",
   "metadata": {},
   "source": [
    "**构造函数 \\_\\_init__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, in_features, out_features):\n",
    "    super(CustomModule, self).__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features)\n",
    "    self.relu = nn.ReLU() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b496a",
   "metadata": {},
   "source": [
    "构造函数 \\_\\_init__ 初始化 CustomModule 实例。它接收两个参数：in_features 和 out_features，分别表示输入和输出特征的维度。\n",
    "\n",
    "- super(CustomModule, self).\\_\\_init__() 调用基类的构造函数来正确初始化 nn.Module。Python3也可写super().\\_\\_init__() 。\n",
    "- self.linear 创建了一个 nn.Linear 层，它是一个全连接层，用于将输入特征线性变换到指定的输出特征维度。\n",
    "- self.relu 创建了一个 nn.ReLU 层，它是一个非线性激活函数，用于增加模型的表达能力。\n",
    "\n",
    "**前向传播 forward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127815ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.linear(x)\n",
    "    x = self.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e041f",
   "metadata": {},
   "source": [
    "forward 方法定义了数据通过 CustomModule 时的计算流程。即定义了输入如何转换为输出。\n",
    "\n",
    "- 输入 x 首先通过 self.linear 全连接层，进行线性变换。\n",
    "- 接着，变换后的输出通过 self.relu ReLU 激活层，引入非线性，去除负值。\n",
    "最终，forward 方法返回通过线性层和激活层处理后的结果。\n",
    "\n",
    "\n",
    "**总结**\n",
    "**在 PyTorch 中，当继承 nn.Module 创建自定义模块时，通常需要重写至少以下两个方法：**\n",
    "\n",
    "1. **\\_\\_init__(self, ...): 构造函数，用于初始化模块的参数或子模块**。在这个方法中，会调用父类的构造函数，并定义模块内部将使用的层和参数。\n",
    "2. **forward(self, x): 前向传播方法，定义了模块的计算流程，即当模块接收输入数据时应该执行的操作**。在 forward 方法中，会使用在 __init__ 方法中定义的层和参数来指定如何处理输入，并返回输出。\n",
    "\n",
    "\n",
    "\n",
    "这两个方法是创建自定义模块时最基本和最重要的部分。根据需要，可能还会重写其他方法。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LiMu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
