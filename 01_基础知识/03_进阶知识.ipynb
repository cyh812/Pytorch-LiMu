{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2098da78",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 基于pytorch的线性代数运算表达"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289523ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.833285Z",
     "iopub.status.busy": "2023-08-18T07:01:43.832377Z",
     "iopub.status.idle": "2023-08-18T07:01:43.839757Z",
     "shell.execute_reply": "2023-08-18T07:01:43.838656Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.arange(20).reshape(5, 2, 2)\n",
    "A.T #矩阵转置\n",
    "B = A.clone() #通过分配内存，将A的一个副本分配给B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdea0f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "两个矩阵的按元素乘法称为*Hadamard积*（Hadamard product）（数学符号$\\odot$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efe4855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.896102Z",
     "iopub.status.busy": "2023-08-18T07:01:43.895401Z",
     "iopub.status.idle": "2023-08-18T07:01:43.903331Z",
     "shell.execute_reply": "2023-08-18T07:01:43.902251Z"
    },
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1],\n",
       "         [  4,   9]],\n",
       "\n",
       "        [[ 16,  25],\n",
       "         [ 36,  49]],\n",
       "\n",
       "        [[ 64,  81],\n",
       "         [100, 121]],\n",
       "\n",
       "        [[144, 169],\n",
       "         [196, 225]],\n",
       "\n",
       "        [[256, 289],\n",
       "         [324, 361]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a91fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420cc92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.946290Z",
     "iopub.status.busy": "2023-08-18T07:01:43.945345Z",
     "iopub.status.idle": "2023-08-18T07:01:43.953195Z",
     "shell.execute_reply": "2023-08-18T07:01:43.952092Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6992, 0.6992],\n",
       "        [0.9081, 0.9081]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定张量沿哪一个轴来通过求和降低维度\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A.sum(axis=[0, 1])\n",
    "A.sum()\n",
    "\n",
    "A = A.float() #计算均值时要先修改数据类型从tensor.long变为float\n",
    "# 求均值\n",
    "A.mean()\n",
    "A.mean(axis=0)\n",
    "sum_A = A.sum(axis=1, keepdims=True) #计算总和或均值时保持轴数不变\n",
    "\n",
    "# 某个轴计算`A`元素的累积总和，注意是累积总和，基本上没什么用\n",
    "A.cumsum(axis=0)\n",
    "\n",
    "x = torch.rand(4)\n",
    "y = torch.ones(4)\n",
    "# 点积是相同位置的按元素乘积的和，输入必须是一维张量\n",
    "torch.dot(x, y)\n",
    "\n",
    "# 矩阵相乘运算，最最重要的；注意矩阵形状\n",
    "x = x.reshape(2,2)\n",
    "y = y.reshape(2,2)\n",
    "x @ y # 等价于torch.mm(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e98c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_2$*范数*是向量元素平方和的平方根：\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f829c100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.100377Z",
     "iopub.status.busy": "2023-08-18T07:01:44.099628Z",
     "iopub.status.idle": "2023-08-18T07:01:44.107745Z",
     "shell.execute_reply": "2023-08-18T07:01:44.106642Z"
    },
    "origin_pos": 140,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b36a33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_1$范数，它表示为向量元素的绝对值之和：\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "01356584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.143775Z",
     "iopub.status.busy": "2023-08-18T07:01:44.142900Z",
     "iopub.status.idle": "2023-08-18T07:01:44.151418Z",
     "shell.execute_reply": "2023-08-18T07:01:44.150335Z"
    },
    "origin_pos": 145,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a43fb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵\n",
    "的*Frobenius范数*（Frobenius norm）是矩阵元素平方和的平方根：\n",
    "$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0a8792ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.156452Z",
     "iopub.status.busy": "2023-08-18T07:01:44.155694Z",
     "iopub.status.idle": "2023-08-18T07:01:44.163608Z",
     "shell.execute_reply": "2023-08-18T07:01:44.162540Z"
    },
    "origin_pos": 150,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "LiMu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
